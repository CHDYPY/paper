# Tuned Models of Peer Assessment in MOOCs

## 摘要

### 作者会议年份

作者：Chris Piech、Jonathan Huang、Zhenghao Chen

会议：ComputerScience

年份：2013

### 概括

提出了一种算法，来判断评分者的可信程度。

## 第一章 介绍

互评的背景，越来越重要。

评分者打出的分数与staff打出的分数差距较大，如何寻找可靠的评分者成为了一个问题。

本文提出了一种模型，通过评分者的历史评分记录与当前的分数来对评分者的可靠性进行评估。

通过实验证明，评分者的可靠性对于评分结果有重要的影响。

## 第二章 数据集

![](E:\a笔记\图片\表一.png)

互评的数据集来自Coursera上的两门相同的人机交互课程。

数据来自两门课程的互评作业，作业是网页设计的评分。每个评分者在参加评分前都要经过评估测试

每个学生会评估五份其他人的作业，五份作业中有一份被称为“ground truth”，即哨兵。据统计，每份作业将会被五个同学评估。

提交的最终分数以所有评分成绩的中位数来确定。

评分将人员划分成了国家和语言组，以减少主观偏见。

数据集的具体分布参照表一。

## 第三章 模型

## 第四章 实验

均方根误差（RMS）

### 模型的公平公正



