# 论文导论

## 作者年份日期

作者：Fei Mi，Dit-Yan Y eung 香港科技大学计算机科学与工程学系

日期：2015

会议：AAAI

## 摘要

这篇论文对于**基数估计**和**序数估计**两个方面各提出了新的思想：

1. 首先，我们对已有的基数对等等级概率图模型提出了新的扩展。这些扩展不仅在基数评价方面具有优越的性能，而且在排序评价方面也优于传统的排序模型。
2. 其次，我们将基数模型与序数模型结合起来，在序数模型中加入基数预测作为先验。这样的结合可以进一步提高基本评估和顺序评估的成绩，为mooc同伴评分的研究指明了一个新的方向。

## 第一章 介绍

大规模在线开放课程(MOOC)最近越来越受到关注，因为它们可以远远超出传统课堂和受众的界限。

虽然每个提供传统的课程由顶尖大学著名教授通常受益最多数百名学生，只有学生，一个在线版本可以很容易地由几个数量级规模，使它可用于全球各行各业的人。

然而，大规模的MOOC对学生评估提出了巨大的挑战。虽然大多数现有的MOOC只提供多项选择题或考试题，可以自动评分，但开放式和自由回答练习或论文无疑是评估许多课程学习结果的必备工具。

不幸的是，这种评估方式令人满意的自动评分超出了目前的技术水平。解决这一问题的实际方法是同伴评分或同伴评估(Godlee et al. 2003;Sadler and Good 2006)，学生也扮演评分者的角色，根据课程教师提供的标准或标准，对其他学生提交的少量作业进行评分。

提交的最终分数通常是评分者给出的同龄人分数的一些总和，比如中位数或平均值。由于学生的背景、目的和参与程度各不相同，应用同伴评分来给学生一个公平的评价他们的学习努力和成绩并不是一件简单的任务。

例如，通过在Coursera平台上监控我校某门mooc课程学生的注册信息和访问IP地址，我们发现这些学生来自大约160个不同的国家。此外，最近的一项研究(Anderson et al. 2014)表明，MOOC中的学生往往会表现出不同的参与风格，这可能与不同的目的相对应。

- 对一些最先进的基数对等等级概率图形模型提出了新的扩展(Piech et al.  2013)。基于平均情况和最差情况的性能标准，我们的模型在基数评价方面都有改进。此外，我们的扩展在序次评价方面也显著优于传统的序次模型。
- 将基数模型和序数模型结合起来，将序数模型与先前的基数预测相加。这样的组合可以进一步提高基本和顺序评估的性能。

## 第二章  相关工作

尽管在互评的工作中，被更多评分者评估的作业在经过模型处理后能得到更加准确的结果，但是这意味着一个评分者将会评估更多的作业。这就会导致评分者在打分的过程中出现一些主观上的松懈，导致评分的准确度下降。



## 第三章 模型

### 序数估计模型的优化

#### 概括

偏执和可信性的定义：

想象一个正态分布的函数，偏执对应于均值，可信度对应于方差。

尽管$PG_3$模型已经提出了评分者的真实分数与可信度之间存在关系，但文中的线性关系过于简单，我们尝试使用概率关系来替代它，这两个新模型分别是$PG_4$和$PG_5$.除此之外，我们还提出了一些其他影响可信度的因素，例如：课程论坛声誉分数、视频小测验的表现、课程论坛的浏览量等。然而这些方法都没有评分者的真实分数有效。因此在本文中只考虑评分者的真实分数。

#### 符号表示

![](C:\Users\lenovo\Desktop\表1.png)

$T_v$表示评分者v的可信度

$b_v$表示评分者v的偏执

$s_u$表示用户u作业的真实分数

$z_u^v$表示用户u作业被评分者v打出的评价分数

#### $PG_4$

###  数据集

实验中使用的同伴评分数据集来自于香港科技大学在Coursera平台上开设的一门名为“中国科学、技术与社会I”的课程。本课程采用的同伴评分方法如下：

- 有3个题目，每一个都要求学生写一篇字数限制的短文(第一题250字，第二题和第三题各500字)。
- 对于每一题，每个学生要求评价3份其他人的作业，尽管最终每个人各个题目的获得的互评数量不完全相等，有一些甚至超过了10。被评作业的分配是由系统自动随机完成的。
- 每个题目由三项标准，第一题的每项标准的评分范围为： 0-7, 0-7, 0-7；二、三题的每项标准的评分范围为： 0-7, 0-7, 0-11.最终的得分由三个标准得到，而三个标准的最终取值是每个标准在同伴互评结果的中位数。

对于每道题目，大约20份提交的作业由课程教师评分。平均而言，每个老师评分的作业被其他四个同学一起进行了评价。

![](C:\Users\lenovo\Desktop\表2.png)

### 基数模型试验结果

从概率模型中可以看出，评分者的信度决定了观测分数的高斯分布的精度参数。

在调节参数的过程中，对于$PG_4$模型，我们主要对影响评分者可信度的概率模型方差$\beta_0$进行微调。对于$PG_5$模型，我们主要对影响评分者的评分函数的概率模型上的$\lambda$进行微调。在实验的过程中，我们发现由于$PG_3$的线性模型结构，它对参数更加敏感。

### 序数评估模型

![](F:\a笔记\图片\AAAI Ordinal Model.png)

$u_i和u_j$表示学生两个学生i和j，$S_{u_i}和S_{u_j}$表示$u_i和u_j$获得的一个真实分数。

### 基数评估模型

$PG_4$和$PG_5$是$PG_3$的变种，他们将模型中评分者的可信性和评分者的真实分数建立了一个概率模型。

其中$PG_4$是伽马分布模型，$PG_5$是高斯分布模型。

如果评分者没有在互评中提交作业，则评分者的可信性将会被看成是最低。

#### 数据集



#### 模型的性能评估

模型使用root-mean-square error (RMSE)均方根误差来评估性能，计算方法是通过教师的打分和模型的预测分数。

表三显示了模型运行了十次后的结果，Median表示取中位数的方法。

![](E:\a笔记\图片\表三.png)

从实验结果可以看出：在Assignment1中$PG_3$的性能要优于$PG_4、PG_5$，但是在Assignment2、Assignment3中$PG_4$和$PG_5$的性能更好。

这说明了将评分者的真实分数与可信性的关系转化为概率模型的效果要优于线性模型。

#### 模型的最坏情况与敏感度

我们将每个模型预测的分数与教师的评估分数进行对比，找出其中的最大值，结果如表4.

![](E:\a笔记\图片\表四.png)

从表看出：$PG_3$的偏置要高于$PG_4和PG_5$，其中$PG_5$的效果最优秀。

但是在$PG_3$中，评分者的观测分数将会受到评分者的真实分数和被评者的真实分数的双重影响，尽管$PG_3$的表现在Assignment1中的表现要优于$PG_4和PG_5$.但是在$PG_5和PG_4$中，评分者的真实分数只会影响到他的可信度。因此在新的模型中，真实分数对评估分数的敏感性要小于$PG_4$。

### 序数评估模型

序数评估模型使用了Bradley-Terry、RBTL、BT+G.

**序数模型**和**基数模型**的结合公式如下：

![](E:\a笔记\图片\基数加序数.png)

其中，预测分数$\mu_u$由基数模型得出，最终求得预测准确率。

假设由BLT模型生成：

![](E:\a笔记\图片\hypothesis.png)

最终，根据预测的准确性，我们给出了测试结果：
![](E:\a笔记\图片\表五.png)

尽管纯序数模型会忽略评分信息，但是最终效果与中位数的准确性相差不大。

### 消融实验

基数模型的实验结果始终好于序数模型，这是因为在基数模型中，使用了更加细粒度的数值，比序数模型的二进制比较效果更加优秀。

我们可以将基数模型的分数信息解释为用户的偏好信息，再借助于序数模型，确定这些偏好，从而得出更好的结果。

为了防止这样的结果被解释为基数模型自身的优势，我们又使用基数模型的评估方法测试了基数+序数模型，测试结果如下：

![](E:\a笔记\图片\表六.png)

从图中可以看出，两个模型的结合可以比纯基数模型获得更好的结果。

